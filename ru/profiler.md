# Оптимизация производительности TensorFlow с помощью профилировщика

[TOC]

Используйте инструменты, доступные с Profiler, чтобы отслеживать производительность ваших моделей TensorFlow. Посмотрите, как ваша модель работает на хосте (CPU), устройстве (GPU) или на комбинации хоста и устройства (а).

Профилирование помогает понять потребление аппаратных ресурсов (время и память) различными операциями (ops) TensorFlow в вашей модели, устранить узкие места в производительности и, в конечном итоге, ускорить выполнение модели.

В этом руководстве вы узнаете, как установить профилировщик, различные доступные инструменты, различные режимы сбора профилировщиком данных о производительности и некоторые рекомендуемые передовые практики для оптимизации производительности модели.

Если вы хотите профилировать производительность вашей модели на [Cloud TPU](https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_profile) , обратитесь к руководству Cloud TPU.

## Установите необходимые компоненты Profiler и GPU

Установите Profiler, загрузив и запустив скрипт [`install_and_run.py`](https://raw.githubusercontent.com/tensorflow/profiler/master/install_and_run.py) [из репозитория GitHub](https://github.com/tensorflow/profiler) .

Для профилирования на GPU необходимо:

1. [Установите CUDA® Toolkit 10.1](https://www.tensorflow.org/install/gpu#linux_setup) или новее. CUDA® Toolkit 10.1 поддерживает профилирование только одного графического процессора. Чтобы профилировать несколько графических процессоров, см. [Профилирование нескольких графических процессоров](#profile_multiple_gpus) . Убедитесь, что версия устанавливаемого драйвера CUDA® не ниже 440,33 для Linux или 441,22 для Windows.

2. Убедитесь, что CUPTI существует на пути:

    ```shell
    /sbin/ldconfig -N -v $(sed 's/:/ /g' <<< $LD_LIBRARY_PATH) | \
    grep libcupti
    ```
3. И все

Если у вас нет CUPTI на пути, добавьте его установочный каталог к `$LD_LIBRARY_PATH` , запустив:

```shell
export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH
```

Выполните `ldconfig` раз, чтобы убедиться, что библиотека CUPTI найдена.

### Профилировать несколько графических процессоров {: id = 'profile_multiple_gpus'}

TensorFlow пока официально не поддерживает профилирование нескольких графических процессоров. Вы можете установить CUDA® Toolkit 10.2 или новее для профилирования нескольких графических процессоров. Поскольку TensorFlow поддерживает версии CUDA® Toolkit только до 10.1, создайте символические ссылки на `libcudart.so.10.1` и `libcupti.so.10.1` .

```shell
sudo ln -s /usr/local/cuda/lib64/libcudart.so.10.2 /usr/local/cuda/lib64/libcudart.so.10.1
sudo ln -s /usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.2 /usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.1
```

Чтобы профилировать конфигурации графических процессоров с несколькими сотрудниками, профилируйте отдельных сотрудников независимо.

## Инструменты профилировщика

Получите доступ к **профилировщику на вкладке «Профиль** » в TensorBoard, которая появляется только после того, как вы захватили некоторые данные модели. В Profiler есть набор инструментов для анализа производительности:

- Обзорная страница
- Анализатор входного трубопровода
- Статистика TensorFlow
- Средство просмотра трассировки
- Статистика ядра GPU

### Обзорная страница

Обзорная страница обеспечивает представление верхнего уровня того, как ваша модель работала во время выполнения профиля. На этой странице представлена сводная страница обзора для вашего хоста и всех устройств, а также некоторые рекомендации по повышению эффективности обучения вашей модели. Вы также можете выбрать отдельные хосты в раскрывающемся списке Host.

На странице обзора отображаются следующие данные:

![изображение](./images/tf_profiler/overview_page.png)

- **Сводка производительности -** отображает общую сводку производительности вашей модели. Сводка производительности состоит из двух частей:

    1. Разбивка времени шага - разбивает среднее время шага на несколько категорий, на которые оно тратится:

        - Компиляция - время, затраченное на компиляцию ядер.
        - Вход - время, потраченное на чтение входных данных.
        - Вывод - время, потраченное на чтение выходных данных.
        - Запуск ядра - время, затрачиваемое хостом на запуск ядер.
        - Время вычислений хоста
        - Время связи между устройствами
        - Время вычислений на устройстве
        - Все остальные, включая накладные расходы Python

    2. Точность вычислений устройства - сообщает процент времени вычислений устройства, в котором используются 16- и 32-разрядные вычисления.

- **График времени шага -** отображает график времени шага устройства (в миллисекундах) по всем выбранным шагам. Каждый шаг разбит на несколько категорий (с разными цветами), на которые тратится время. Красная область соответствует части времени шага, в течение которого устройства бездействовали в ожидании входных данных от хоста. Зеленая область показывает, сколько времени устройство действительно работало.

- **10 основных операций TensorFlow на устройстве -** отображает операции на устройстве, которые выполнялись дольше всех.

    Каждая строка отображает собственное время операции (в процентах от времени, затраченного всеми операциями), совокупное время, категорию и имя.

- **Среда выполнения -** отображает высокоуровневую сводку среды выполнения модели, включая:

    - Количество используемых хостов
    - Тип устройства (GPU / TPU)
    - Количество ядер устройства

- **Рекомендации для следующих шагов -** сообщает, когда модель ограничена входными данными, и рекомендует инструменты, которые вы можете использовать для обнаружения и устранения узких мест производительности модели.

### Анализатор входного трубопровода

Когда программа TensorFlow считывает данные из файла, она начинается с вершины графа TensorFlow конвейерным способом. Процесс чтения разделен на несколько этапов обработки данных, соединенных последовательно, где выход одного этапа является входом для следующего. Эта система чтения данных называется *входным конвейером* .

Типичный конвейер чтения записей из файлов состоит из следующих этапов:

1. Чтение файла
2. Предварительная обработка файлов (необязательно)
3. Передача файлов с хоста на устройство

Неэффективный конвейер ввода может серьезно замедлить работу вашего приложения. Приложение считается **привязанным к вводу,** когда оно проводит значительную часть времени в конвейере ввода. Используйте информацию, полученную с помощью анализатора входного конвейера, чтобы понять, где входной конвейер неэффективен.

Анализатор входного конвейера немедленно сообщает вам, связана ли ваша программа с входными данными, и проведет вас через анализ на стороне устройства и хоста для устранения узких мест производительности на любом этапе входного конвейера.

См. Руководство по производительности конвейера ввода, чтобы узнать о рекомендуемых передовых методах оптимизации конвейеров ввода данных.

#### Панель входного конвейера

Чтобы открыть анализатор входного конвейера, выберите **Профиль** , затем выберите **input_pipeline_analyzer** в раскрывающемся **списке Инструменты.**

![изображение](./images/tf_profiler/input_pipeline_analyzer.png)

Панель управления состоит из трех разделов:

1. **Сводка - резюмирует** общий конвейер ввода с информацией о том, связано ли ваше приложение с вводом и, если да, на сколько
2. **Анализ на стороне устройства -** отображает подробные результаты анализа на стороне устройства, включая время шага устройства и диапазон времени, затраченного устройством на ожидание входных данных по ядрам на каждом шаге.
3. **Анализ на стороне хоста -** показывает подробный анализ на стороне хоста, включая разбивку времени обработки ввода на хосте.

#### Сводка входного конвейера

Сводка сообщает, привязана ли ваша программа к вводу, показывая процент времени, затраченного устройством на ожидание ввода от хоста. Если вы используете стандартный конвейер ввода, оснащенный инструментами, инструмент сообщает, на что тратится большая часть времени обработки ввода.

#### Анализ на стороне устройства

Анализ на стороне устройства дает представление о времени, затраченном на устройство по сравнению с хостом, и о том, сколько времени устройство было потрачено на ожидание входных данных от хоста.

1. **Время шага в зависимости от номера шага -** отображает график времени шага устройства (в миллисекундах) по всем выбранным шагам. Каждый шаг разбит на несколько категорий (с разными цветами), на которые тратится время. Красная область соответствует части времени шага, в течение которого устройства бездействовали в ожидании входных данных от хоста. Зеленая область показывает, сколько времени устройство действительно работало.
2. **Статистика времени шага -** сообщает среднее значение, стандартное отклонение и диапазон ([минимум, максимум]) времени шага устройства.

#### Анализ на стороне хоста

Анализ на стороне хоста сообщает о разбивке времени обработки ввода (времени, затраченного на `tf.data` API) на хосте по нескольким категориям:

- **Чтение данных из файлов по запросу -** время, затрачиваемое на чтение данных из файлов без кэширования, предварительной выборки и чередования.
- **Заблаговременное чтение данных из файлов -** время, потраченное на чтение файлов, включая кэширование, предварительную выборку и чередование.
- **Предварительная обработка данных -** время, затрачиваемое на операции предварительной обработки, такие как распаковка изображения.
- **Постановка данных в очередь для передачи на устройство -** время, затраченное на помещение данных в очередь подачи перед передачей данных на устройство.

Разверните **Статистика операций ввода,** чтобы просмотреть статистику для отдельных операций ввода и их категорий с разбивкой по времени выполнения.

![изображение](./images/tf_profiler/input_op_stats.png)

Появится таблица исходных данных с каждой записью, содержащей следующую информацию:

1. **Операция ввода -** показывает имя операции ввода TensorFlow.
2. **Счетчик -** показывает общее количество экземпляров выполнения операции за период профилирования.
3. **Общее время (в мс) -** показывает совокупную сумму времени, потраченного на каждый из этих экземпляров.
4. **Общее время% -** показывает общее время, затраченное на операцию, как долю от общего времени, затраченного на обработку ввода.
5. **Общее время самостоятельной работы (в мс) -** показывает совокупную сумму собственного времени, потраченного на каждый из этих экземпляров. Самостоятельное время здесь измеряет время, проведенное внутри тела функции, за исключением времени, затраченного на функцию, которую она вызывает.
6. **Общее время самостоятельной работы%** . Показывает общее собственное время как долю от общего времени, затраченного на обработку ввода.
7. **Категория** . Показывает категорию обработки входной операции

### Статистика TensorFlow

Инструмент TensorFlow Stats отображает производительность каждой операции TensorFlow, которая выполняется на хосте или устройстве во время сеанса профилирования.

![изображение](./images/tf_profiler/tf_stats.png)

Инструмент отображает информацию о производительности на двух панелях:

- На верхней панели отображается до четырех круговых диаграмм:

    1. Распределение времени самостоятельного выполнения каждой операции на хосте
    2. Распределение времени самостоятельного выполнения каждого типа операции на хосте
    3. Распределение времени самостоятельного выполнения каждой операции на устройстве
    4. Распределение времени самостоятельного выполнения каждого типа операции на устройстве

- На нижней панели отображается таблица с данными об операциях TensorFlow с одной строкой для каждой операции и одним столбцом для каждого типа данных (сортируйте столбцы, щелкая заголовок столбца). Нажмите кнопку «Экспортировать как CSV» в правой части верхней панели, чтобы экспортировать данные из этой таблицы в виде файла CSV.

    Обратите внимание, что:

    - Если какие-либо операции имеют дочерние операции:

        - Общее "накопленное" время операции включает время, проведенное внутри дочерней операции.
        - Общее время операции не включает время, проведенное внутри дочерней операции.

    - Если операция выполняется на хосте:

        - Процент общего времени автономной работы на устройстве, вызванный операцией, будет равен 0.
        - Совокупный процент от общего времени, проведенного на устройстве до этой операции включительно, будет равен 0.

    - Если на устройстве выполняется операция:

        - Процент общего времени нахождения на хосте, понесенный этой операцией, будет равен 0
        - Совокупный процент от общего времени нахождения на хосте до и с учетом этой операции будет равен 0.

Вы можете включить или исключить время простоя на круговых диаграммах и в таблице.

### Средство просмотра трассировки

Средство просмотра трассировки отображает временную шкалу, которая показывает:

- Продолжительность операций, выполненных вашей моделью TensorFlow
- Какая часть системы (хост или устройство) выполнила операцию. Обычно хост выполняет операции ввода, предварительно обрабатывает данные обучения и передает их на устройство, в то время как устройство выполняет фактическое обучение модели.

Средство просмотра трассировки позволяет выявлять проблемы производительности в вашей модели, а затем предпринимать шаги для их решения. Например, на высоком уровне вы можете определить, занимает ли обучение вводных данных или модели большую часть времени. Переходя вниз по иерархии, вы можете определить, какие операции выполняются дольше всего.

Обратите внимание, что средство просмотра трассировки ограничено 1 миллионом событий на устройство.

#### Интерфейс программы просмотра трассировки

Когда вы открываете средство просмотра трассировки, оно отображает ваш последний запуск:

![изображение](./images/tf_profiler/trace_viewer.png)

Этот экран содержит следующие основные элементы:

1. **Панель временной шкалы -** показывает операции, которые устройство и хост выполняли с течением времени.
2. **Панель** сведений - показывает дополнительную информацию для операций, выбранных на панели временной шкалы.

Панель временной шкалы содержит следующие элементы:

1. **Верхняя панель -** содержит различные вспомогательные элементы управления.
2. **Ось времени -** показывает время относительно начала кривой.
3. **Метки разделов и дорожек -** каждый раздел содержит несколько дорожек и имеет треугольник слева, который можно щелкнуть, чтобы развернуть или свернуть раздел. Для каждого обрабатывающего элемента в системе есть одна секция.
4. **Селектор инструментов -** содержит различные инструменты для взаимодействия со средством просмотра трассировки, такие как масштабирование, панорамирование, выбор и синхронизация. Используйте инструмент «Время», чтобы отметить временной интервал.
5. **События -** показывают время, в течение которого была выполнена операция, или продолжительность мета-событий, таких как шаги обучения.

##### Разделы и дорожки

Средство просмотра трассировки содержит следующие разделы:

- **Один раздел для каждого узла устройства** , помеченный номером микросхемы устройства и узлом устройства в микросхеме (например, `/device:GPU:0 (pid 0)` ). Каждый раздел узла устройства содержит следующие дорожки:
    - **Шаг -** показывает продолжительность шагов тренировки, которые выполнялись на устройстве.
    - **TensorFlow Ops -** . Показывает операции, выполненные на устройстве
    - **XLA Ops -** показывает [операции XLA](https://www.tensorflow.org/xla/) (ops), которые выполнялись на устройстве, если XLA - используемый компилятор (каждая операция TensorFlow транслируется в одну или несколько операций XLA. Компилятор XLA переводит операции XLA в код, который выполняется на устройстве).
- **Один раздел для потоков, работающих на ЦП хост-машины,** обозначен как **«Host Threads»** . Раздел содержит по одной дорожке для каждого потока ЦП. Примечание. Информацию, отображаемую рядом с метками разделов, можно игнорировать.

##### События

События на временной шкале отображаются разными цветами; сами цвета не имеют особого значения.

### Статистика ядра GPU

Этот инструмент показывает статистику производительности и исходную операцию для каждого ядра с ускорением на GPU.

![изображение](./images/tf_profiler/gpu_kernel_stats.png)

Инструмент отображает информацию на двух панелях:

- На верхней панели отображается круговая диаграмма, которая показывает ядра CUDA, у которых есть наибольшее общее время.

- На нижней панели отображается таблица со следующими данными для каждой уникальной пары ядро-оператор:

    - Ранг в порядке убывания общей истекшей продолжительности работы графического процессора, сгруппированный по паре ядро-операционная система.
    - Имя запущенного ядра
    - Количество регистров графического процессора, используемых ядром
    - Общий размер общей (статической + динамической) общей памяти, используемой в байтах.
    - Размер блока, выраженный как `blockDim.x, blockDim.y, blockDim.z`
    - Размеры сетки выражаются как `gridDim.x, gridDim.y, gridDim.z`
    - Имеет ли оператор право использовать TensorCores
    - Содержит ли ядро инструкции TensorCore
    - Имя оператора, запустившего это ядро
    - Количество появлений этой пары ядро-операция
    - Общее затраченное время GPU в микросекундах
    - Среднее время, затраченное на GPU в микросекундах
    - Минимальное затраченное время GPU в микросекундах
    - Максимальное затраченное время GPU в микросекундах

## Собирать данные о производительности

Профилировщик TensorFlow собирает действия хоста и трассировки графического процессора вашей модели TensorFlow. Вы можете настроить Profiler для сбора данных о производительности либо в программном режиме, либо в режиме выборки.

- Программный режим с использованием обратного вызова `tf.keras.callbacks.TensorBoard` (tf.keras.callbacks.TensorBoard)

    ```python
    # Profile from batches 10 to 15
    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,
                                                 profile_batch='10, 15')

    # Train the model and use the TensorBoard Keras callback to collect
    # performance profiling data
    model.fit(train_data,
              steps_per_epoch=20,
              epochs=5,
              callbacks=[tb_callback])
    ```

- Программный режим с использованием API функции `tf.profiler`

    ```python
    tf.profiler.experimental.start('logdir')
    # Train the model here
    tf.profiler.experimental.stop()
    ```

- Программный режим с использованием диспетчера контекста

    ```python
    with tf.profiler.experimental.Profile('logdir'):
        # Train the model here
        pass
    ```

Примечание. Слишком долгая работа Profiler может привести к нехватке памяти. Рекомендуется профилировать не более 10 шагов за раз. Избегайте профилирования первых нескольких пакетов, чтобы избежать неточностей из-за накладных расходов на инициализацию.

- Режим выборки - выполнение профилирования по запросу с помощью `tf.profiler.experimental.server.start()` для запуска сервера gRPC с запуском вашей модели TensorFlow. После запуска сервера КПГР и работает модель, вы можете захватить профиль через кнопку **Profile Capture** в TensorBoard профиль плагина. Используйте сценарий в разделе «Установить профилировщик» выше, чтобы запустить экземпляр TensorBoard, если он еще не запущен.

    В качестве примера,

    ```python
    # Start a gRPC server at port 6009
    tf.profiler.experimental.server.start(6009)
    # ... TensorFlow program ...
    ```

![изображение](./images/tf_profiler/capture_profile.png)

Вы можете указать URL-адрес службы профилей или имя TPU, продолжительность профилирования и сколько раз профилировщик должен повторять попытки захвата профилей, если сначала не удалось.

## Лучшие практики для оптимальной работы модели

Используйте следующие рекомендации, применимые к вашим моделям TensorFlow, для достижения оптимальной производительности.

В общем, выполните все преобразования на устройстве и убедитесь, что вы используете последнюю совместимую версию библиотек, таких как cuDNN и Intel MKL, для своей платформы.

### Оптимизировать конвейер входных данных

Эффективный конвейер ввода данных может значительно повысить скорость выполнения вашей модели за счет сокращения времени простоя устройства. Чтобы сделать конвейер ввода данных более эффективным, подумайте о том, чтобы использовать следующие передовые практики, подробно описанные [здесь:](https://www.tensorflow.org/guide/data_performance)

- Предварительная выборка данных
- Распараллелить извлечение данных
- Распараллелить преобразование данных
- Кэшировать данные в памяти
- Векторизация пользовательских функций
- Уменьшите использование памяти при применении преобразований

Кроме того, попробуйте запустить модель с синтетическими данными, чтобы проверить, не является ли входной конвейер узким местом для производительности.

### Повышение производительности устройства

- Увеличение размера обучающего мини-пакета (количество обучающих выборок, используемых на устройство за одну итерацию обучающего цикла)
- Используйте статистику TF, чтобы узнать, насколько эффективно выполняются операции на устройстве
- Используйте `tf.function` для выполнения вычислений и, при необходимости, включите флаг `experimental_compile`
- Сведите к минимуму операции хоста Python между шагами и уменьшите количество обратных вызовов. Расчет показателей каждые несколько шагов, а не на каждом шаге
- Держите вычислительные блоки устройства занятыми
- Отправляйте данные на несколько устройств параллельно
- Оптимизируйте компоновку данных, чтобы в первую очередь отдавать предпочтение каналам (например, NCHW, а не NHWC). Некоторые графические процессоры, такие как NVIDIA® V100, лучше работают с форматом данных NHWC.
- Рассмотрите возможность использования 16-битных числовых представлений, таких как `fp16` , формат с плавающей запятой половинной точности, определенный IEEE, или формат Brain с плавающей запятой [bfloat16.](https://cloud.google.com/tpu/docs/bfloat16)
- Рассмотрите возможность использования [API смешанной точности Keras](https://www.tensorflow.org/guide/keras/mixed_precision)
- При обучении на графических процессорах используйте TensorCore. Ядра графического процессора используют TensorCore, когда точность равна fp16, а размеры ввода / вывода делятся на 8 или 16 (для int8)

## Дополнительные ресурсы

- См. [Полное руководство по профилировщику TensorBoard,](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) чтобы реализовать рекомендации этого руководства.
- Посмотрите [доклад о профилировании производительности в TF 2](https://www.youtube.com/watch?v=pXHAQIhhMhI) на TensorFlow Dev Summit 2020.
